<!DOCTYPE html>
<html lang="en-US">
    <head>

        <meta charset="UTF-8">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2C44LTKBE1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-2C44LTKBE1');
</script>
        <!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
            <title>Introduction to Optimization</title>
    
        <!-- Meta tags -->
        
        <meta name="keywords" content="Copula, Probability Integral Transform">
        <meta name="author" content="John Della Rosa" >
        <meta name="description" content="Introduction to copulas, probability integral transforms, multivariate distributions.">
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
        <link rel="apple-touch-icon" sizes="180x180" href="https://johndellarosa.github.io/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="https://johndellarosa.github.io/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="https://johndellarosa.github.io/favicon-16x16.png">
        <link rel="manifest" href="https://johndellarosa.github.io/site.webmanifest">
        <link rel="canonical" href="https://johndellarosa.github.io/projects/distribution-book/copula"/>    
        <link rel="stylesheet" href="https://johndellarosa.github.io/style.css"> 
<!-- 
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
      

        <script src="../../math.js" type="text/javascript"></script> -->

    </head>
    <body>
        <div class="navbar">
            <b style="margin-right:10px">John Della Rosa</b>| 
            <a href="https://johndellarosa.github.io/">Home</a>|
            <a href="https://johndellarosa.github.io/resume">Resume</a>|
            <a href="https://johndellarosa.github.io/biography">About</a>|
            <a href="https://johndellarosa.github.io/projects">Projects</a>|
            <a href="https://johndellarosa.github.io/miscellaneous">Misc</a>|
            <a href="https://www.linkedin.com/in/johndellarosa/" target="_blank">Linkedin</a>|
            <a href="https://github.com/johndellarosa" target="_blank">Github</a>|
            <a href="https://play.google.com/store/apps/developer?id=JohnDellaRosa" target="_blank">Google Play</a>|
            <a href="https://apps.apple.com/us/developer/john-della-rosa/id1684177615" target="_blank">Apple Store</a>
        
        </div>
        <h2><a href= "table-of-contents.html">Distribution Textbook (Work in Progress)</a></h2>

<h3>by John Della Rosa</h3>
        <div id="text-contents" style="width:90%; margin:auto">
            <div id="Copulas">
                <h1>Introduction to Optimization</h1>
                <h2>Basic Terminology</h2>
                
                <h3>Recommended Prerequesites</h3>
                <ol>
                    <li><a href="https://johndellarosa.github.io/projects/biophysics-book/probability">Probability</a></li>
                    <li><a href="./probability-2.html">Probability II</a></li>
                    <!-- <li><a href="./sampling-continuous.html">Sampling</a></li> -->
                    <!-- <li><a href="./multivariate-intro">Introduction to Multivariate Distributions</a></li> -->
               
                </ol>


                <h2>Types of Constraints</h2>


                <h3>Equality Constraints</h3>
                $$g_i(x)=0,\quad i=1,2,\dots,m$$

                <h3>Inequality Constraints</h3>
                Inequality constraints specify that certain functions of the variables must be less than or equal to, or greater than or equal to, a constant value.

                $$h_j(x)\leq 0,\quad j=1,2,\dots,p$$
                $$k_k(x)\geq 0,\quad k=1,2,\dots,q$$

                <h3>Feasible Region</h3>

                The feasible region is the set of all points \(x\) that satisfy all the constraints.

                $$\mathcal{F}=\{x\in\mathbb{R}^n|g_i(x)=0,h_j(x)\leq 0\}$$

                <h4>Types of Solutions</h4>
                <ul>
                    <li>Global Optimum: The best possible solution over the entire feasible region.</li>
                    <li>Local Optimum: The best solution within a neighborhood of points</li>
                    <li>Boundary Solutions: Solutions that lie on the edge of the feasible region</li>
                    <li>Interior Solutions: Solutions that lie strictly within the feasible region</li>
                </ul>



                <h2>Lagrange Multipliers</h2>

                Consider the optimization problem:

                $$\min_{x}f(x)$$
                which is subject to

                $$g_i(x)=0;\quad i=1,2,\dots,m$$

                The Lagrangian is given by
                $$\mathcal{L}(x,\lambda)=f(x)-\sum_{i=1}^m\lambda_ig_i(x)$$


                Optimality Conditions:

                $$\nabla_{X}\mathcal{L}(x^*,\lambda^*)=\nabla f(x^*)-\sum_{i=1}^m\lambda_{i}^{*}\nabla g_i(x^*)=0$$

                Primal feasibility:

                $$g_i(x^*)=0,\quad \forall i$$

                <h3>Example</h3>
                $$\min_{x,y} f(x,y)=x^2+y^2$$
                Subject to:
                $$g(x,y)=x+y-1=0$$
                Lagrangian:
                $$\mathcal{L}(x,y,\lambda)=x^2+y^2-\lambda(x+y-1)$$
                Stationarity Conditions:

                $$\frac{\partial\mathcal{L}}{\partial x}=2x-\lambda=0\Longrightarrow\lambda=2x$$
                $$\frac{\partial\mathcal{L}}{\partial y}=2y-\lambda=0\Longrightarrow\lambda=2y$$
                Equation \(\lambda\) and solve:

                $$2x=2y\Longrightarrow x=y$$
                $$x+y=1\Longrightarrow 2x=1\Longrightarrow x=\frac{1}{2},y=\frac{1}{2}$$

                <h2>Optimization with Inequality Constraints</h2>
                

$$\min_{x\in\mathbb{R}^n}f(x)$$
Subject to Constraints:
$$\text{Equality Constraints:}\quad g_i(x)=0,\quad i=1,2,\dots,m$$
$$\text{Inequality Constraints:}\quad h_j(x)\leq 0,\quad j=1,\dots,p$$
Lagrangian
$$\mathcal{L}(x,\lambda,\mu)=f(x)-\sum_{i=1}^{m}\lambda_ig_i(x)-\sum_{j=1}^{p}\mu_j h_j(x)$$

<ul>
    <li>\(\lambda\in\mathbb{R}^{m}\): Lagrange multiplier for equality constraints</li>
    <li>\(\mu\in\mathbb{R}^p\): Lagrange multipliers (dual variables) for inequality constraints</li>
</ul>

<h3>Convexity</h3>
<h4>Convex Set</h4>
A Set \(\mathcal{C}\subeq\mathbb{R}^n\) is convex if, for any \(x,y \in \mathcal{C}\) and \(\theta\in[0,1]\), the point \(\theta x+(1-\theta) y\in \mathcal{C}\).

<h4>Convex Function</h4>
A function \(f:\mathbb{R}^n\to\mathbb{R}\) is convex if its domain is convex and, for all x,y in its domain:

$$f(\theta x+(1-\theta)y)\leq \theta f(x) + (1-\theta)f(y)$$

<h3>KKT Conditions</h3>
<h4>Stationarity</h4>
$$\nabla f(x^*)-\sum_{i=1}^{m}\lambda_{i}^{*}\nabla g_i(x^*)-\sum_{j=1}^{p}\mu_{j}^{*}\nabla h_j(x^*)=0$$
In unconstrained optimization, setting \(\nabla f(x^*)=0\) identifies stationary points. However, when constraints are present, the feasible direction is limited by the constraints. Therefore, the gradient of the objective function must be balanced by the gradients of the constraints to prevent movement outside the feasible region. 



<h4>Primal Feasibility</h4>
$$g_i(x^*)=0,\quad h_j(x^*)\leq 0$$
The solution \(x^*\) must satisfy all the original problem's constraints. This is self-explanatory.

<h4>Dual Feasibility</h4>
$$\mu_{j}^{*}\geq 0,\quad \forall j$$
The Lagrange multipliers associated with the inequality constraints must be non-negative. For why this is necessary, if the multipliers were negative, that would imply increasing the constraint violation would improve the objective function, which contradicts optimality. 


<h4>Complementary Slackness</h4>
$$\mu_{j}^{*}h_j(x^*)=0,\quad \forall j$$
For each inequality constraint: \(h_j(x)\leq 0\):
<ul>
    <li>If \(\mu_{j}^{*}\gt0\), then \(h_j(x^*)=0\) (the constraint is active)</li>
    <li>If \(h_j(x^*)\lt 0\), then \(\mu_j^{*}=0\) (the constraint is inactive)</li>
</ul>

This ensures that only the constraints that are binding at the optimum have a non-zero influence on the solution.






            </div>



             




                <div id="Exercises">
                    <h2>Constrained Optimization Practice Problems</h2>

                    <ol>

                    </ol>
    
    
                </div>
        </div>
        <script>
            var coll = document.getElementsByClassName("collapsible");
            var i;
    
            for (i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function() {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.display === "block") {
                content.style.display = "none";
                } else {
                content.style.display = "block";
                }
            });
            } 
            </script>
</body>
</html>
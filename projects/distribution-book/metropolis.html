<!DOCTYPE html>
<html lang="en-US">
    <head>

        <meta charset="UTF-8">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2C44LTKBE1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-2C44LTKBE1');
</script>
        <!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
            <title>Metropolis Algorithm</title>
    
        <!-- Meta tags -->
        
        <meta name="keywords" content="Copula, Probability Integral Transform">
        <meta name="author" content="John Della Rosa" >
        <meta name="description" content="Introduction to the Metropolis Algorithm for sampling.">
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
        <link rel="apple-touch-icon" sizes="180x180" href="https://johndellarosa.github.io/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="https://johndellarosa.github.io/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="https://johndellarosa.github.io/favicon-16x16.png">
        <link rel="manifest" href="https://johndellarosa.github.io/site.webmanifest">
        <link rel="canonical" href="https://johndellarosa.github.io/projects/distribution-book/metropolis"/>    
        <link rel="stylesheet" href="https://johndellarosa.github.io/style.css"> 
<!-- 
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
      

        <script src="../../math.js" type="text/javascript"></script> -->

    </head>
    <body>
        <div class="navbar">
            <b style="margin-right:10px">John Della Rosa</b>| 
            <a href="https://johndellarosa.github.io/">Home</a>|
            <a href="https://johndellarosa.github.io/resume">Resume</a>|
            <a href="https://johndellarosa.github.io/biography">About</a>|
            <a href="https://johndellarosa.github.io/projects">Projects</a>|
            <a href="https://johndellarosa.github.io/miscellaneous">Misc</a>|
            <a href="https://www.linkedin.com/in/johndellarosa/" target="_blank">Linkedin</a>|
            <a href="https://github.com/johndellarosa" target="_blank">Github</a>|
            <a href="https://play.google.com/store/apps/developer?id=JohnDellaRosa" target="_blank">Google Play</a>|
            <a href="https://apps.apple.com/us/developer/john-della-rosa/id1684177615" target="_blank">Apple Store</a>
        
        </div>
        <h2><a href= "table-of-contents.html">Distribution Textbook (Work in Progress)</a></h2>

<h3>by John Della Rosa</h3>
        <div id="text-contents" style="width:90%; margin:auto">
            <div id="Copulas">
                <h1>Metropolis Algorithm</h1>

                
                <h3>Recommended Prerequesites</h3>
                <ol>
                    <li><a href="https://johndellarosa.github.io/projects/biophysics-book/probability">Probability</a></li>
                    <li><a href="./probability-2.html">Probability II</a></li>
                    <li><a href="./sampling-continuous.html">Sampling</a></li>
                    <li><a href="./markov-chain.html">Introduction to Markov Chains</a></li>
                    <li><a href="./markov-chain-monte-carlo.html">Markov Chain Monte Carlo</a></li>
                </ol>
            
                <h2><a href="./metropolis-visualizer.html">Metropolis Algorithm</a></h2>
            The Metropolis Algorithm is one of the most common MCMC methods. Its primary purpose is to generate a sequence of samples from a target distribution \(\pi(x)\), 
            especially when \(\pi(x)\) is known only up to a normalizing constant or is too complex for direct sampling.

            <h3>Conceptual Framework</h3>
            <h4>Markov Chain Construction</h4>
            The algorithm constructs a Markov Chain whose stationary distribution is the desired target distribution \(\pi(x)\).

            <h4>Proposal Mechanism</h4>
            At each iteration, a new candidate state \(x^*\) is proposed based on the current state \(x_t\), using a proposal distribution \(q(x^*|x_t)\). 

            <h4>Acceptance Criterion</h4>
            The proposed state \(x^*\) is accepted or rejected based on an acceptance probability \(\alpha\), which ensures that the chain has the correct stationary distribution.

            <h3>Detailed Balance Condition</h3>
            The Metropolis algorithm satisfies the detailed balance condition, which is a sufficient condition for the chain to have \(\pi(x)\) as its stationary distribution

            $$\pi(x_{t})q(x^*|x_t)\alpha(x_t,x^*)=\pi(x^*)q(x_t|x^*)\alpha(x^*,x_t)$$

            <h3>Symmetric Proposal Distribution</h3>
            In the original Metropolis algorithm, the proposal distribution \(q(x^*|x_t)\) is symmetric:
            $$q(x^*|x_t)=q(x_t|x^*)$$

            This symmetry simplifies the acceptance probability to:
            $$\alpha=\min\left(1,\frac{\pi(x^*)}{\pi(x_t)}\right)$$

            <h3>Random Walk Behavior</h3>
            The algorithm often employs a random walk proposal, where the next state is proposed by adding a random perturbation to the current state. 

            <h3>Example</h3>

            Suppose we want to sample from a univariate target distribution \(\pi(x)\) defined on \(\mathbb{R}\). The target distribution is proportional to:

            $$\pi(x)\propto e^{-(x^4-16x^2+5x)}$$

            This distribution is complex and does not have a standard form, making direct sampling challenging. 

            <h4>Define Target Distribution</h4>
            We define the unnormalized target density function:

            $$\pi(x)\propto e^{-(x^4-16x^2+5x)}$$

            The normalizing constant isn't needed for the Metropolis algorithm. 


            <h4>Choose the Proposal Distribution</h4>
            Select a proposal distribution \(q(x'|x)\), which is the distribution of proposing a new state \(x'\) given the current state \(x\).

            We'll use a symmetric normal proposal distribution centered at the current state:

            $$q(x'|x)=\mathcal{N}(x';x,\sigma^2)$$
            where \(\sigma^2\) is the variance of the proposal distribution. 
            
            Example: Set \(\sigma=2\).

            <h4>Initialize the Chain</h4>

            Choose an initial value \(x_0\) for the Markov Chain. 

            $$x_0=0$$

            <h4>Metropolis Algorithm Iteration</h4>
            For \(t=0\) to \(T-1\), perform the following steps to generate \(x_{t+1}\):

            <h5>Generate a Proposal</h5>

            Sample a candidate value \(x^*\) from the proposal distribution:

            $$x^*\sim q(x^*|x_t)=\mathcal{N}(x^*;x_t,\sigma^2)$$

            Example Calculation:
            <ul>
                <li>Suppose at iteration \(t\), the current state is \(x_t=0\)</li>
                <li>Sample \(x^*\) from \(\mathcal{N}(0,4)\) and obtain \(x^*=1.5\)</li>
            </ul>

            <h5>Compute the Acceptance Probability</h5>
            Since the proposal distribution is symmetric, \(q(x^*|x_t)=q(x_t|x^*)\), so the acceptance probability simplifies to:

            $$\alpha=\min\left(1,\frac{\pi(x^*)}{\pi(x_t)}\right)$$

            Compute the ratio of target densities:

            <ol>
                <li>Compute \(\pi(x^*)\):
                    $$\pi(x^*)=e^{-(x^{*4}-16x^{*2}+5x^*)}$$
                </li>
                <li>Compute \(\pi(x_t)\) similarly</li>
            </ol>

            Example:

            $$\pi(1.5)=e^{-(1.5^4-16\times 1.5^2+5\times 1.5)}=e^{28.3125}$$

            $$\pi(0)=e^{-(0^4-16\times0^2+5\times0)}=e^{0}=1$$

            Since this ratio is greater than 1, the acceptance probability \(\alpha=1\).

            <h5>Accept or Reject the Proposal</h5>
            <ul>
                <li>Generate a uniform random number \(u\sim \mathcal{U}(0,1)\)</li>
                <li>If \(u \leq \alpha\), accept the proposal: \(x_{t+1}=x^*\)</li>
                <li>Else, reject the proposal: \(x_{t+1}=x_t\)</li>
            </ul>

            Example:<br>
            <ul>
                <li>Generate \(u=0.7\)</li>
                <li>Since \(u=0.7\leq\alpha=1\), accept the proposal.</li>
                <li>Set \(x_{t+1}=1.5\)</li>
            </ul>

            <h5>Record the State</h5>
            Continue the process for a large number of iterations to obtain a sequence of samples \(\{x_t\}_{t=1}^T\).

            <h5>Post-Processing</h5>
            <ul>
                <li><strong>Burn-in Period</strong>: Discard the initial \(B\) samples (e.g., first 1,000 iterations) to reduce the influence of the starting value.</li>
                <li><strong>Thinning (optional)</strong>: To reduce autocorrelation, keep every \(k\)-th sample</li>
   

            </ul>


    <h2>Metropolis-Hastings</h2>
            <h3>Introduction</h3>
While the original Metropolis algorithm uses a symmetric proposal distribution (the probability of proposing a move from state \(x\) to \(y\) is the same as from \(y\) to \(x\)), 
The Metropolis-Hastings algorithm relaxes this requirement. It introduces an acceptance probability that corrects for the asymmetry, ensuring that the Markov chain still converges to the target distribution.

<h3>Algorithm</h3>
<h4>Acceptance Probability</h4>
The acceptance probability (\alpha(x,x')\) is defined as:
$$\alpha(x,x')=\min\left(1,\frac{\pi(x')q(x|x')}{\pi(x)q(x'|x)}\right)$$

<h4>Initialization</h4>
Start with an initial state \(x_0\).

<h4>iteration</h4>
For \(t=0\) to \(N-1\):
<ol>
    <li>Proposal: Generate a proposed state \(x'\) from the proposal distribution (q(x'|x_t)\).</li>
    <li>Acceptance Probability: Compute \(\alpha(x_t,x')\)</li>
    <li>Acceptance/Rejection:
        <ol type="a">
            <li>Generate a uniform random number \(u\sim\mathcal{U}(0,1)\)</li>
            <li>If \(u\leq\alpha(x_t,x')\), accept the proposal and set \(x_{t+1}=x'\)</li>
            <li>Else, reject the proposal and set \(x_{t+1}=x_t\)</li>
        </ol>
    </li>
    <li></li>
</ol>
<h4>Repeat</h4>
Repeat: Continue the process to generate a sequence of \(\{x_t\}\)

<h3>Metropolis-Hastings Detailed Balance</h3>
$$\pi(x)P(x\rightarrow x')=\pi(x')P(x'\rightarrow x)$$

<h3>Example</h3>
Suppose we want to sample from the target distribution:
$$\pi(x)=\frac{1}{Z}e^{-\frac{x^2}{2}},\quad x\in\mathbb{R}$$
Since this is a standard normal distribution, we know the value of \(Z\), but normalization constants aren't important for this algorithm.

<h4>Proposal Distribution</h4>
We will choose a normal distribution centered at the current state \(x_t\):
$$q(x'|x_t)=\mathcal{N}(x';x_t,\sigma^2)$$
where \(\sigma^2\) is the variance of the proposal distribution.

<h4>Algorithm Steps</h4>
<h5>Initialization</h5>
Let \(x_0=0\).
<h5>Iteration</h5>
For \(t=0\) to \(N-1\):
<h6>Proposal</h6>
Sample: \(x'\sim\mathcal{N}(x_t,\sigma^2)\)
<h6>Acceptance Probability</h6>
Since \(q(x'|x_t)=q(x_t|x')\) (symmetric proposal), the acceptance probability simplifies to:
$$\alpha(x_t,x')=\min\left(1,\frac{\pi(x')}{\pi(x_t)}\right)$$

Since \(pi(x)=e^{-\frac{x^2}{2}}\) (ignoring the constant \(Z\)), we have:
$$\alpha(x_t,x')=\min\left(e^{-\frac{x'^2-x_{t}^2}{2}}\right)$$

<h6>Acceptance/Rejection</h6>
<ol>
    <li>Generate \(u\sim\mathcal{U}(0,1)\)</li>
    <li>If \(u\leq\alpha(x_t,x')\), accept \(x'\) and set \(x_{t+1}=x'\)</li>
    <li>Else, set \(x_{t+1}=x_t\)</li>
</ol>
<h6>Repeat</h6>
Continue for \(N\) iterations.

<h3>Considerations</h3>
<h4>Choice of Proposal Distribution</h4>
A small variance leads to high acceptance rates but slow exploration. A large variance leads to low acceptance rates but can explore the space more quickly.





            </div>



             




                <div id="Exercises">
                    <h2>Metropolis Algorithm Practice Problems</h2>

                    <ol>
                        
                    </ol>
    
    
                </div>
        </div>
        <script>
            var coll = document.getElementsByClassName("collapsible");
            var i;
    
            for (i = 0; i < coll.length; i++) {
            coll[i].addEventListener("click", function() {
                this.classList.toggle("active");
                var content = this.nextElementSibling;
                if (content.style.display === "block") {
                content.style.display = "none";
                } else {
                content.style.display = "block";
                }
            });
            } 
            </script>
</body>
</html>
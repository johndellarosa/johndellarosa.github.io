<!DOCTYPE html>
<html lang="en-US">
    <head>

        <meta charset="UTF-8">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2C44LTKBE1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-2C44LTKBE1');
</script>
        <!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> -->
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
            <title>Compilation</title>
    
        <!-- Meta tags -->
        
        <meta name="keywords" content="Copula, Probability Integral Transform">
        <meta name="author" content="John Della Rosa" >
        <meta name="description" content="Introduction to distribution distance metrics">
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
        <link rel="apple-touch-icon" sizes="180x180" href="https://johndellarosa.github.io/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="https://johndellarosa.github.io/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="https://johndellarosa.github.io/favicon-16x16.png">
        <link rel="manifest" href="https://johndellarosa.github.io/site.webmanifest">
        <link rel="canonical" href="https://johndellarosa.github.io/projects/c-book/compiling"/>    
        <link rel="stylesheet" href="https://johndellarosa.github.io/style.css"> 
<!-- 
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
      

        <script src="../../math.js" type="text/javascript"></script> -->

    </head>
    <body>
        <div class="navbar">
            <b style="margin-right:10px">John Della Rosa</b>| 
            <a href="https://johndellarosa.github.io/">Home</a>|
            <a href="https://johndellarosa.github.io/resume">Resume</a>|
            <a href="https://johndellarosa.github.io/biography">About</a>|
            <a href="https://johndellarosa.github.io/projects">Projects</a>|
            <a href="https://johndellarosa.github.io/miscellaneous">Misc</a>|
            <a href="https://www.linkedin.com/in/johndellarosa/" target="_blank">Linkedin</a>|
            <a href="https://github.com/johndellarosa" target="_blank">Github</a>|
            <a href="https://play.google.com/store/apps/developer?id=JohnDellaRosa" target="_blank">Google Play</a>|
            <a href="https://apps.apple.com/us/developer/john-della-rosa/id1684177615" target="_blank">Apple Store</a>
        
        </div>
        <h2><a href= "table-of-contents.html">C in Python Textbook (Work in Progress)</a></h2>

<h3>by John Della Rosa</h3>
        <div id="text-contents" style="width:90%; margin:auto">
            <div id="Introduction">
                <h1>Introduction</h1>
                <h2>Basic Compilation</h2>
                
                <h3>Recommended Prerequesites</h3>
                <ol>
                    <li><a href="https://johndellarosa.github.io/projects/biophysics-book/probability">Probability</a></li>
                    <li><a href="./probability-2.html">Probability II</a></li>
                    <li><a href="./sampling-continuous.html">Sampling</a></li>
                    <li><a href="./multivariate-intro">Introduction to Multivariate Distributions</a></li>
               
                </ol>

                <h3>Recommended Software</h3>
                SIMD (Single Instruction, Multiple Data) is a set of instructions that allows a single instruction to operate on multiple data points simultaneously. This can significantly speed up computations, especially in numerical applications. In this section, we will explore how to use SIMD instructions in C with the AVX2 (Advanced Vector Extensions 2) instruction set.

                Intel's AVX2 extends the register width to 256 bits, allowing for operations on eight 32-bit floating-point numbers or four 64-bit floating-point numbers in a single instruction. This can lead to substantial performance improvements in applications that require heavy numerical computations.

                The library we will use for SIMD operations is the <code>immintrin.h</code> header, which provides access to AVX2 intrinsics. Intrinsics are functions that map directly to assembly instructions, allowing us to write high-performance code without delving into assembly language.

                <h3>High Level Explanation</h3>

                                <table>
                  <thead>
                      <tr>
                          <th>Instrinsic</th>
                          <th>Semantics</th>
                      </tr>
                  </thead>
                  <tbody>
                      <tr>
                          <td><code>_mm256_loadu_pd(addr)</code></td>
                          <td>Unaligned load of 4 doubles</td>
                      </tr>
                    <tr>
                          <td><code>_mm256_load_pd(addr)</code></td>
                          <td>Aligned (32-byte) load of 4 doubles</td>
                      </tr>
                        <tr>
                            <td><code>_mm256_storeu_pd(addr, vec)</code></td>
                            <td>Unaligned store of 4 doubles</td>
                        </tr>
                        <tr>
                            <td><code>_mm256_store_pd(addr, vec)</code></td>
                            <td>Aligned (32-byte) store of 4 doubles</td>
                        </tr>
                        <tr>
                            <td><code>_mm256_stream_pd(addr, vec)</code></td>
                            <td>Store of 4 doubles, non-temporal (avoids cache)</td>
                        </tr>
                        <tr>
                            <td><code>_mm256_maskload_pd(addr, mask)</code></td>
                            <td>Load with mask</td>

                        </tr>                        
                  </tbody>
              </table>

              <h3>Operations</h3>

              AVX2 provides a rich set of operations that can be performed on vectors of doubles, such as common arithmetic operations (addition, subtraction, multiplication, division), as well as fused multiply-add (FMA), which is as the name suggests, a single instruction that performs multiplication followed by addition. This can be particularly useful in numerical algorithms where such operations are common.:

                <table>
                    <thead>
                        <tr>
                            <th>Instrinsic</th>
                            <th>Semantics</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>_mm256_add_pd(a, b)</code></td>
                            <td>Adds two vectors of 4 doubles</td>
                        </tr>
                            <tr>
                                <td><code>_mm256_sub_pd(a, b)</code></td>
                                <td>Subtracts two vectors of 4 doubles</td>
                            </tr>
                            <tr>
                                <td><code>_mm256_mul_pd(a, b)</code></td>
                                <td>Multiplies two vectors of 4 doubles</td>
                            </tr>
                            <tr>
                                <td><code>_mm256_div_pd(a, b)</code></td>
                                <td>Divides two vectors of 4 doubles</td>
    
                            </tr>                        
                        <tr>
                            <td><code>_mm256_fmadd_pd(a, b, c)</code></td>
                            <td>Fused multiply-add: computes a * b + c</td>
                    </tbody>
                </table>

                AVX2 also has logical operations that can be performed on vectors of doubles, such as bitwise AND, OR, and XOR. These operations can be useful for manipulating data at the bit level:

                <table>
                    <thead>
                        <tr>
                            <th>Instrinsic</th>
                            <th>Semantics</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>_mm256_and_pd(a, b)</code></td>
                            <td>Bitwise AND of two vectors of 4 doubles</td>
                        </tr>
                        <tr>
                            <td><code>_mm256_or_pd(a, b)</code></td>
                            <td>Bitwise OR of two vectors of 4 doubles</td>
                        </tr>
                        <tr>
                            <td><code>_mm256_xor_pd(a, b)</code></td>
                            <td>Bitwise XOR of two vectors of 4 doubles</td>

                        </tr>   
                        <tr>
                            <td><code>_mm256_andnot_pd(a, b)</code></td>
                            <td>Bitwise AND NOT of two vectors of 4 doubles</td>
                        </tr>                     
                    </tbody>
                </table>

                In addition to these basic operations, AVX2 also provides a set of comparison operations that can be used to compare vectors of doubles. These operations return a mask indicating which elements satisfy the comparison condition:

                <table>
                    <thead>
                        <tr>
                            <th>Instrinsic</th>
                            <th>Semantics</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>_mm256_cmp_pd(a, b, _CMP_EQ_OQ)</code></td>
                            <td>Compares two vectors of 4 doubles for equality</td>
                        </tr>
                        <tr>
                            <td><code>_mm256_cmp_pd(a, b, _CMP_LT_OQ)</code></td>
                            <td>Compares two vectors of 4 doubles for less than</td>
                        </tr>
                        <tr>
                            <td><code>_mm256_cmp_pd(a, b, _CMP_GT_OQ)</code></td>
                            <td>Compares two vectors of 4 doubles for greater than</td>

                        </tr>                        
                    </tbody>
                </table>

                <h3>Example</h3>

                <pre>
                <code>
                #include &lt;stddef.h&gt;
                #include &lt;immintrin.h&gt;

                void add_arrays(const double *a, const double *b, double *out, size_t length) {
                size_t i = 0;
                // Vectorized loop: process 4 doubles per iteration
                for (; i+3 &lt; length; i += 4) {
                    __m256d va = _mm256_loadu_pd(&a[i]); // unaligned load of vector a
                    __m256d vb = _mm256_loadu_pd(&b[i]); // unaligned load of vector b
                    __m256d vc = _mm256_add_pd(va, vb); // vector addition
                    -MM256_storeu_pd(&out[i], vc); // unaligned store of result
                }

                // Scalar tail for any remaining elements
                for (; i &lt; length; ++i) {
                    out[i] = a[i] + b[i];
                }
            }
                </code>
                </pre>


                
                Inside the terminal, navigate to the directory where you saved the c script and compile it into a shared library (DLL) using the following command:

                <pre>
                <code>
                    gcc -O3 -mavx2 -shared -fPIC vector_ops_add_avx2.c -o libvector_ops_add_avx2.dll
                </code>
                </pre>

                This time, we used the O3 optimization flag to enable heavy compiler optimizations, and the -mavx2 flag to enable AVX2 instructions.

                <h4>Using in Python</h4>





                Now, we can use this DLL in Python using the ctypes library. Create a Python script named use_my_functions.py (name doesn't have to be the same as the c file) with the following content:

                <pre>
                <code>
                import ctypes
                import numpy as np
                import pandas as pd
                import os

                # 1. Load the AVX2-enabled library
                lib = ctypes.CDLL(os.path.abspath("libvector_ops_add_avx2.dll"))

                # 2. Define C function signature
                lib.add_arrays.argtypes = (
                    np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags="C_CONTIGUOUS"),
                    np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags="C_CONTIGUOUS"),
                    np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags="C_CONTIGUOUS"),
                    ctypes.c_size_t,
                )
                lib.add_arrays.restype = None

                # 3. Prepare data in a pandas DataFrame
                df = pd.DataFrame({
                    "A": np.random.rand(1_000_000),
                    "B": np.random.rand(1_000_000),
                })

                # 4. Allocate output array and call C function
                def add_columns(df, col_a, col_b, col_out):
                    a = df[col_a].values
                    b = df[col_b].values
                    out = np.empty_like(a)
                    lib.add_arrays(a, b, out, a.size)
                    df[col_out] = out

                # 5. Usage example
                print("Before:\n", df.head())
                add_columns(df, "A", "B", "C")
                print("After adding A + B into C:\n", df.head())
                </code>
                </pre>

                <h2>Other Functions</h2>

                _mm256_set1_pd

                The _mm256_set1_pd intrinsic is used to set all elements of a 256-bit AVX2 register to the same double value. This is useful for initializing vectors with a constant value.

                <pre><code>
                    double factor = 5.0;
                    v4df vf = _mm256_set1_pd(factor);
                    // vf now contains [5.0, 5.0, 5.0, 5.0]
                    for (i = 0; i + 3 < n; i += 4) {
                        v4df v = _mm256_loadu_pd(&arr[i]);
                        v = _mm256_mul_pd(v, vf);
                        _mm256_storeu_pd(&arr[i], v);
                    }
                </code></pre>
                
                _mm256_broadcast_sd

                The _mm256_broadcast_sd intrinsic is used to broadcast a single double value across all elements of a 256-bit AVX2 register. This is similar to _mm256_set1_pd but may be more efficient in certain cases, especially when the value is already in memory.

                

                </div>



             




        </div>

</body>
</html>
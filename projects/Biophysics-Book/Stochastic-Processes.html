<!DOCTYPE html>
<html lang="en-US">
    <head>

        <meta charset="UTF-8">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2C44LTKBE1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-2C44LTKBE1');
</script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
            <title>Stochastic Processes</title>
    
        <!-- Meta tags -->
        
        <meta name="keywords" content="Stochastic process, biology, random walk, brownian motion, diffusion, markov chain, poisson">
        <meta name="author" content="John Della Rosa" >
        <meta name="description" content="This chapter builds off the probability and statistics chapter to introduce stochastic processes, starting with Markov chains. Brownian Motion and Poisson Processes are also covered.">
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
        <link rel="apple-touch-icon" sizes="180x180" href="https://johndellarosa.github.io/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="https://johndellarosa.github.io/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="https://johndellarosa.github.io/favicon-16x16.png">
        <link rel="manifest" href="https://johndellarosa.github.io/site.webmanifest">
            
        <link rel="stylesheet" href="https://johndellarosa.github.io/style.css"> 
        <!-- </script>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
      

        <script src="../../math.js" type="text/javascript"></script> -->

    </head>
    <body>
        <div class="navbar">
            <b style="margin-right:10px">John Della Rosa</b>| 
            <a href="https://johndellarosa.github.io/index.html">Home</a>|
            <a href="https://johndellarosa.github.io/resume.html">Resume</a>
            <!-- <a href="./index.html#education">Education</a>
            <a href="./index.html#experience">Experience</a>
            <a href="./index.html#skills">Skills</a> -->
            |
            <a href="https://johndellarosa.github.io/biography.html">About</a>|
            <a href="https://johndellarosa.github.io/projects.html">Projects</a>|
            <a href="https://johndellarosa.github.io/Miscellaneous.html">Misc</a>|
            <a href="https://www.linkedin.com/in/johndellarosa/" target="_blank">Linkedin</a>|
            <a href="https://github.com/johndellarosa" target="_blank">Github</a>|
            <a href="https://play.google.com/store/apps/developer?id=JohnDellaRosa" target="_blank">Google Play</a>|
            <a href="https://apps.apple.com/us/developer/john-della-rosa/id1684177615" target="_blank">Apple Store</a>
        
        </div>
<h2><a href= "Table-of-Contents.html">Biophysical Chemistry Textbook (Work in Progress)</a></h2>
<h3>by John Della Rosa</h3>
        <div id="text-contents" style="width:90%; margin:auto">
            <div id="Stochastic-Processes">
                <h1>Stochastic Processes</h1>
                <h2>Introduction</h2>
                This chapter will focus on both discrete-time and continuous-time stochastic processes. 
                We will begin with Markov chains and Random Walks. Later, Brownian Motion and Poisson processes will be covered. 
                This will be a math-intensive chapter, introducing some basics of stochastic calculus, which the reader is not assumed to have experience with. 
                 
                <h2>Discrete Time Stochastic Processes</h23>
    
                <h3>Discrete-Time Markov Chains</h3>
    
                Imagine a system where a protein is in one of two states: A or E. Each minute you observe its state, and it has the ability to go from state A to E or E to A, but it does not necessarily switch. We will denote these observational periods at \(t=0, 1, \ldots\)
                <br><br>
                An important assumption that we will make is that only the current state determines the probability of switching conformations  the state that it was in prior to this observation have <b>no</b> impact on the chances. 
                E.g. if we are at t=n, the state that the protein was in at t=n-1 has no impact on the probability for t=n+1. 
                This is called the <b>Markov property</b>.
                
                <br><br>
                
                For simplicity's state, we will assume that these observations are discrete events and not worry about what happens outside of our regular 1-minute interval observations. 
                
    
                <figure><a href="https://commons.wikimedia.org/wiki/File:Markovkate_01.svg#/media/File:Markovkate_01.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/2/2b/Markovkate_01.svg" alt="Markovkate 01.svg" style="max-height: 300px;" ></a><br><br>By <a href="//commons.wikimedia.org/wiki/User:Joxemai4" title="User:Joxemai4">Joxemai4</a> - <span class="int-own-work" lang="en">Own work</span>, <a href="https://creativecommons.org/licenses/by-sa/3.0" title="Creative Commons Attribution-Share Alike 3.0">CC BY-SA 3.0</a>,&nbsp;&nbsp;&nbsp; <a href="https://commons.wikimedia.org/w/index.php?curid=10284158">Link</a></figure>
    
                We are given the dynamics of the protein conformational changes: 
                            <ul>
                    <li>If the protein is in state A, it has a 40% chance of switching to the E state by the next observation and a 60% chance of remaining in the A state. 
                    </li>
                    <li>If the protein is in state E, it has a 70% chance of switching to the A conformation by the next observation and a 30% chance of remaining in the E state</li>
                            </ul>
    
                Given a start state, we can determine the probability, not just of the next minute, but subsequent observations as well. 
                
                This can be represented naturally using Linear Algebra. 
    
                $$\begin{bmatrix}
                0.6 & 0.4\\ 
                0.7 & 0.3
                \end{bmatrix}$$
    
                Where the row is the starting state and the column is the final state. 
    <br><br>
                
                For our starting state vector, if we are in the A state, we can put a 1 in the first column and a 0 elsewhere:
    
                $$\begin{bmatrix}
                1 & 0
                \end{bmatrix}$$
                It is not actually necessary to know the starting state to make statements on the probability of the state over time. We can have our start be a probability distribution instead. 
                
                To get the probability of being in each state after 1 interval, we can multiply the two:
                $$\begin{bmatrix}
                1 & 0
                \end{bmatrix}\begin{bmatrix}
                            0.6 & 0.4\\ 
                            0.7 & 0.3
                            \end{bmatrix}=\begin{bmatrix}
                0.6 & 0.4
                \end{bmatrix}$$
    
                We observe a 60% chance of remaining in state A and a 40% chance of transitioning to state E as expected at t=1. 
                
                We can use this result to see what the probability of being in each state are at t=2
    
                $$\begin{bmatrix}
                0.6 & 0.4
                \end{bmatrix}\begin{bmatrix}
                            0.6 & 0.4\\ 
                            0.7 & 0.3
                            \end{bmatrix}$$
                            $$=\begin{bmatrix}
                0.6*0.6+0.7*0.4 & 0.6*0.4+0.4*0.3
                \end{bmatrix}$$
                $$=\begin{bmatrix}
                0.64 & 0.36
                \end{bmatrix}$$
                We can view this as plugging in a probability distribution into a Markov chain rather than knowing the initial state.
                A general formula for the probability distribution at time t=n would thus be:
    
                $$\begin{bmatrix}
                p_{A,t=0} & p_{E,t=0}
                \end{bmatrix}\begin{bmatrix}
                            p_{A\rightarrow A} & p_{A\rightarrow E}\\ 
                            p_{E\rightarrow A} & p_{E\rightarrow E}
                            \end{bmatrix}^n$$
                But what are the long-run probabilities? What if we just came across this natively (assuming the same dynamics) - what would we expect our chances of finding it in a given state are? 
                
                For an analytical solution, we can try to find a stationary point for the transition matrix:<br>
                <br>
                If the state distribution will not change over time, then it would have this property:

                $$P T = P = P I$$
                where P is the state distribution vector, T is the transition matrix, and I is the appropriate sized identity matrix. This is a straightforward eigenvector calculation.

                <br><br>

                Numerically, we can figure out what the distribution would be by taking the limit as \(n\rightarrow\infty\).
    
                <br><br>
                <img src="Markov_states.png" alt="Time evolution of states in markov chain" style="margin:auto; display: block;  width:clamp(300px,30vw, 600px)"/>
                Python code:
                <code style="margin: auto; width: 50%;"><pre>
    initial_prob_vector = np.array([1,0])
    transition_matrix = np.array([[0.6,0.4],[0.7,0.3]])
    time_points = np.arange(10)
    markov_df = pd.DataFrame(index=time_points,columns=['A','E'])
    current_prob = initial_prob_vector
    for i in range(len(time_points)):
        markov_df.loc[i] = current_prob
        current_prob = np.matmul(current_prob, transition_matrix)
    markov_df.plot(xlabel="Iteration",
        ylabel="Fraction",
        title="Evolution of State Makeup Over Time")
    plt.show()</pre>
                </code>
    
                What happens if the initial state were [0,1] instead of [1,0]? This can be checked using the code provided, but it will end up converging to the same values.
    
    
                Additionally, we are not restricted to just 2 states, our probability vector could have m columns for m possible states and our transition matrix would be mxm. 
                Markov chains can even be abstracted to infinite-state versions, although some properties change, which are beyond the scope of this textbook.
    
                Furthermore, the concept can be extended to continuous time processes. 
                <br><br>
    
    
                <h3>Random Walks and Diffusion</h3>
                Let us consider a number line containing all integers, centered at 0. 
                Place a particle at x=0. At every time increment, there is a change to its x position according to the following dynamics:
                $$P(\Delta x_t=1)=0.5$$
                $$P(\Delta x_t=-1)=0.5$$
                What will the resulting distribution look like? 
                If you are familiar with probability theory and remember the Central Limit Theorem, you might be able to predict that it will begin to approach a Gaussian distribution. 
                Well, the maximum possible deviation should be t if all the \(\Delta x_t\) are the same. 
                If each step is independent and the probability of a left movement is the same as a right movement, 
                then we can conclude that every individual path is equally likely. However, the number of paths you can take to get to x=0 after 10 steps is not the same number of paths where you'd end up at x=10. 
                We can alternatively parameterize the paths in terms of lefts and rights, similar to a coin flip. This ends up being a Bernoulli distribution and the multiplicity of paths is given by the binomial distribution. 
                
                <br><br>
                This is an application of Markov chains where each state is connected to the two adjacent numbered states. 
                
    
                <br><br>
    
                The following depicts a simulation of 5000 particles at various time points using Python.
                <img src="Diffusion.png" alt="1D Random walk over time" style="margin:auto; display: block;  width:clamp(300px,60vw, 900px)"/>
                Python code:
                <code style="margin: auto; width: 50%;"><pre>
    particles = np.zeros(5000)
    fig, axes = plt.subplots(4,figsize=(16,12))
    bins = [-31+2*i for i in range(0,31)]
    for i in range(31):
        if (i % 10 == 0):
            axes[i//10].hist(particles, bins = bins,density=True,histtype='step')
            axes[i//10].set(ylabel='Density',title=f't={i}')
        dice_rolls = np.random.rand(5000)
        movement = np.where(dice_rolls < 0.5,1,-1)
        particles += movement
    axes[-1].set(xlabel="x")
    plt.show()</pre>
                </code>
                <br>
    
                We can easily extend this model to a higher number of dimensions by having independent random walks along each axis. 
    
    <img src="Diffusion2D.png" alt="2D random walk over time" style="margin:auto; display: block;  width:clamp(300px,60vw, 900px)"/>
    Python code:
    <code style="margin: auto; width: 50%;"><pre>
np.random.seed(1)
particles_x = np.zeros(5000)
particles_y = np.zeros(5000)
bins = [-31+2*i for i in range(0,31)]
fig, axes = plt.subplots(2,2,figsize=(16,12))
axes = axes.flatten()
j=0
for i in range(51):
    if (i in [0,10,25,50]):
        ax = axes[j].hist2d(particles_x,
        particles_y, bins = bins,
        density=True)
        axes[j].set(ylabel='y',
        title=f't={i}',
        xlabel='x')
        fig.colorbar(ax[3])
        j+=1
    dice_rolls = np.random.rand(5000)
    movement = np.where(dice_rolls < 0.5,1,-1)
    particles_x += movement
    dice_rolls = np.random.rand(5000)
    movement = np.where(dice_rolls < 0.5,1,-1)
    particles_y += movement
plt.show()</pre>
    </code>
    <br>
    
    
                Another area is the concept of a biased walk; i.e. one where the jumps in one direction are favored. We used 50% probabilities for each direction in our initial model, but there's no need for it to be this way. 
                We could have just as easily set \(P(\Delta x=+1)=0.75\) instead. We would observe a fraction still winding up in the negative integers.
    
                <img src="Biased_Diffusion.png" alt="Random walk with drift" style="margin:auto; display: block;  width:clamp(300px,60vw, 900px)"/>
                Python code:
                <code style="margin: auto; width: 50%;"><pre>
    particles = np.zeros(5000)
    fig, axes = plt.subplots(4,sharex=True,figsize=(16,12))
    bins = [-31+2*i for i in range(0,31)]
    for i in range(31):
        if (i % 10 == 0):
            axes[i//10].hist(particles, bins = bins,density=True,histtype='step')
            axes[i//10].set(ylabel='Density',title=f't={i}')
        dice_rolls = np.random.rand(5000)
        movement = np.where(dice_rolls < 0.75,1,-1) # changed from 0.5 to 0.75
        particles += movement
    axes[-1].set(xlabel="x")
    plt.show()</pre>
                </code>
                <br>

                Alternatively, we could think about having the probabilities remain 50% for each direction but add a drift component that gets added at each step. 
                
                <br><br>
                Of course, this is not a realistic model, as particles don't discretely jump, but it becomes a better approximation as the limit as the scale of distance and time go to 0. 
                This will be more precisely defined later.
    
                <h2>Continuous-Time Stochastic Processes</h2>
                There are a few ways we can go from our discrete random walk to continuous-time stochastic processes:
                <ol>
                    <li>Keep the jump size the same, but have random times between jump that are drawn from a continuous distribution (Continuous Time Random Walk)</li>
                    <li>Scale the step size as well as time interval and have our stochastic variable be continuous in both the domain (time) and image ("distance") (Brownian Motion)</li>
                </ol>
                The second option, Brownian Motion, is much more common in terms of sharing the behavior we wish to model.
                However, we will revisit the concept of randomly distributed wait times with Poisson processes later in this chapter.

                <h3>Brownian Motion</h3>
                Brownian motion can be thought of as the continuous analogue of random walks. 
                It is defined by the following properties (<a href="https://www.math.uchicago.edu/~lawler/finbook.pdf">https://www.math.uchicago.edu/~lawler/finbook.pdf</a>):
                <ol>
                    <li>\(B_0=0\)</li>
                    <li>\(B_t\) is almost surely continuous</li>
                    <li>\(B_t\) has independent increments</li>
                    <li>\(B_t-B_s\sim N(\mu=0,\sigma^2=t-s)\text{ where }0\leq s\leq t\)</li>
                </ol>
    
                Now to explain the properties in further detail.
    
                $$B_0=0$$
                This is mainly a convention, as it is possible to have a process undergoing Brownian Motion starting elsewhere, but you would just have to add a constant.
    
                $$B_t\text{ is almost surely continuous}$$
                This is more of a theoretical property which we need not be concerned with. For the intents and purposes of this book, 
                we can just interpret this as stating that Brownian motion is a continuous path with no jumps. 
    
                $$B_t\text{ has independent increments}$$
                Let \(0< s< t\).
                The value of \(B_s-B_0\) is independent of \(B_t-B_s\). It is important that when we select the two intervals that they do not overlap. 
                It is fine to have the endpoint of one be the start of the other however.
    
                $$B_t-B_s\sim N(\mu=0,\sigma^2=t-s)\text{ where }0\leq s\leq t$$
    
                A segment of Brownian motion is normally distributed with a variance equal to the time between the start and end points with mean 0. 
                
                <img src="BrownianMotionSimulation.gif" alt="Brownian Motion Simulation Gif" style="margin:auto; display: block;  width:clamp(400px,50vw, 800px)"/>
                Python code:
                <code style="margin: auto; width: 50%;"><pre>
B=np.zeros(3)
dt = 1e-5
np.random.seed(0)

brownian_df = pd.DataFrame(columns=['t',1,2,3])


brownian_df.loc[0] = [0,*B]
for i in range (1,100001):
    
    dB = np.random.normal(size=3)*np.sqrt(dt)
    B += dB
    brownian_df.loc[i] = [i*dt,*B]
        
fig, ax = plt.subplots(figsize=(8,6))
ax.set_xlim(0,1)
ax.set_ylim(-3,3)

lineA, = ax.plot([],linewidth=0.75)
lineB, = ax.plot([],linewidth=0.75)
lineC, = ax.plot([],linewidth=0.75)

def animate(frame_num):
    lineA.set_data((brownian_df.loc[:frame_num*1000]['t'],
                    brownian_df.loc[:frame_num*1000][1]))
    lineB.set_data((brownian_df.loc[:frame_num*1000]['t'],
                    brownian_df.loc[:frame_num*1000][2]))
    lineC.set_data((brownian_df.loc[:frame_num*1000]['t'],
                    brownian_df.loc[:frame_num*1000][3]))

    plt.title(
        f"Brownian Motion Simulation (t={frame_num*10}ms)")
    return lineA,lineB
                    
plt.ylabel("$B_t$")
plt.xlabel("Time (s)")
plt.legend(['1','2','3'])
anim = FuncAnimation(fig, animate, frames=100, interval=100)
anim.save('BrownianMotionSimulation.gif')
plt.show()          </pre>
                </code>
    
                <h4>Stochastic Differential Equations</h4>
                Brownian motion can be expanded on to include a drift term and scaling coefficient for the brownian motion.

                A generalized form for the dynamics of a stochastic differential equation are:

                $$dX_t=\mu(x,t)dt+\sigma(x,t)dW$$
                where \(X_t\) is the stochastic variable, \(\mu\) is the drift, \(\sigma\) is the volatility, and dW is the Brownian motion increment

                For basic Brownian motion, we can now write this as

                $$dX_t=dW$$

                Let us look at the continuous version of a random walk with drift:

                $$dX_t=2dt+dW$$

                <img src="BrownianMotionDriftSimulation.gif" alt="Brownian Motion with Drift Simulation Gif" style="margin:auto; display: block;  width:clamp(400px,50vw, 800px)"/>
                Python code:
                <code style="margin: auto; width: 50%;"><pre>
X=np.zeros(3)
dt = 1e-5
mu = 2
np.random.seed(0)

brownian_df = pd.DataFrame(columns=['t',1,2,3])


brownian_df.loc[0] = [0,*X]
for i in range (1,100001):
    
    dB = np.random.normal(size=3)*np.sqrt(dt)
    X += (mu*dt+dB)
    brownian_df.loc[i] = [i*dt,*X]
        
fig, ax = plt.subplots(figsize=(8,6))
ax.set_xlim(0,1)
ax.set_ylim(-2,5)

lineA, = ax.plot([],linewidth=0.75)
lineB, = ax.plot([],linewidth=0.75)
lineC, = ax.plot([],linewidth=0.75)

def animate(frame_num):
    lineA.set_data((brownian_df.loc[:frame_num*1000]['t'],
                    brownian_df.loc[:frame_num*1000][1]))
    lineB.set_data((brownian_df.loc[:frame_num*1000]['t'],
                    brownian_df.loc[:frame_num*1000][2]))
    lineC.set_data((brownian_df.loc[:frame_num*1000]['t'],
                    brownian_df.loc[:frame_num*1000][3]))

    plt.title(
        f"Brownian Motion w/ Const Drift Simulation (t={frame_num*10}ms)")
    return lineA,lineB
                    
plt.ylabel("$X_t$")
plt.xlabel("Time (s)")
plt.legend(['1','2','3'])
anim = FuncAnimation(fig, animate, frames=100, interval=100)
anim.save('BrownianMotionDriftSimulation.gif')
plt.show()</pre>
                </code>

                <h4>Ito's Lemma</h4>
                A function of a stochastic variable is also a stochastic variable. But how do we describe its dynamics? 
                <b>Ito's Lemma</b> does exactly that. There is also the Stratonovich formulation of stochastic calculus, but we will not get into that. 
                <br><br>
                Let \(X_t\) be a stochastic variable whose dynamics are 

                $$dX_t=\mu(X_t,t)dt+\sigma(X_t,t)dW$$
                and Let f be a function of \(X_t\) and t where the following partials exist and are continuous, then Ito's lemma states

                $$df(X_t,t)= \partial_t f(X_t,t)dt+ \partial_{x}f(X_t,t) dX_t+\frac{1}{2}\partial_{xx}f (X_t,t)  d\lt X\gt_t$$

                Where \(d\lt X\gt_t=\sigma(X_t,t)^2dt\)

                <h5>Brownian Motion Squared Example</h5>

                Let \(f(x)=x^2\), then the dynamics of \(f(B_t)\) are

                $$d(B_t^2)=2B_tdB_t+dt$$

                While a single simulation is not proof, you can observe how in the example simulation, there is an overall upward trend over time for \(B_t^2\) as \(B_t\) is more likely to be further from 0 as t increases (\(B_t\sim N(0,t)\)). The fluctuations become more drastic as \(B_t\) gets further from 0 as well.


                <img src="BrownianMotionSquared.gif" alt="Brownian Motion Squared Gif" style="margin:auto; display: block;  width:clamp(400px,50vw, 800px)"/>
                
                One interesting thing of note is that you can see in the dynamics that the \(f(B_t)\) will never be negative. 
                As \(B_t\rightarrow 0\), \(\sigma(B_t,t)\rightarrow 0\). The dynamics then become like \(dX_t=dt\), which is a deterministic upward drift. Because Brownian motion is continuous, the function can never become negative without going through 0. This makes sense as a real number squared must be non-negative, but you can justify that through the dynamics even if you didn't know you got the SDE as a result of squaring an underlying variable. 
                This can be more useful for something like a Bessel process where the behavior would not be as obvious (and in fact the properties depend on the value of n). 

                <br><br>
                Python code:
                <code style="margin: auto; width: 50%;"><pre>
B=0
dt = 1e-4
np.random.seed(2)

brownian_df = pd.DataFrame(columns=['t',1,2])


brownian_df.loc[0] = [0,B,B**2]
for i in range (1,100001):
    
    dB = np.random.normal()*np.sqrt(dt)
    B += dB
    brownian_df.loc[i] = [i*dt,B,B**2]
        
fig, ax = plt.subplots(figsize=(8,6))
ax.set_xlim(0,10)
ax.set_ylim(-10,50)

lineA, = ax.plot([],linewidth=0.75)
lineB, = ax.plot([],linewidth=0.75)


def animate(frame_num):
    lineA.set_data((brownian_df.loc[:frame_num*1000]['t'],
                    brownian_df.loc[:frame_num*1000][1]))
    lineB.set_data((brownian_df.loc[:frame_num*1000]['t'],
                    brownian_df.loc[:frame_num*1000][2]))

    plt.title(
        f"Brownian Motion Simulation (t={frame_num//10}.{frame_num%10}s)")
    return lineA,lineB
                    
plt.ylabel("$y$")
plt.xlabel("Time (s)")
plt.legend(['$B_t$','$(B_t)^2$',])
anim = FuncAnimation(fig, animate, frames=100, interval=100)
anim.save('BrownianMotionSquared.gif')
plt.show()          </pre>
                </code>


                <h3>Poisson Process</h3>
                When we were working with discrete-time Markov chains, we had a matrix or depiction of
                $$P(X_{i,t=n+1}|X_{j,t=n})$$
                where \(X_i\) is the new possible state and \(X_j\) is the current state. 
                These probabilities are implicitly given based on the time interval. We do not consider what happens in between observation periods; it is possible that we observe the same state in consecutive observations, but the protein went from A to E then back to A in between.
                To get to continuous-time stochastic processes, we can take the limit as the time between observation periods goes to 0.
    <br><br>
                For a full derivation, see <a href="https://www.math.uchicago.edu/~lawler/finbook.pdf">Lawler's Stochastic Calculus book</a> chapter 6.
                
    <br><br>
                Let us first consider a process that can only increase. In a biology context, we can say that this is the total amount of mRNA produced over a period (not the mRNA level since mRNA can degrade and would go down). 
                Let assume that there is an mRNA production rate \(\lambda\) and define \(p(s)\) to be the probability that at least 1 mRNA moecule is produced during the interval [t,t+s]. 
                Then the probability of 1 mRNA molecule being produced in a short interval is approximately the rate times the duration of time. This can be formalized as 
                $$p(\Delta t)=\lambda \Delta t+o(\Delta t)$$
    
                Let \(X_s\) be the total number of molecules of mRNA produced by time t=s, T be the first time that a molecule of mRNA is produced, or formally:
    
                $$T=\text{inf}\{s:X_s=1\}$$
    
                From this, it can be shown that the probability that no molecules have been produced during an interval of length t is
                
                $$P\{T>t\}=e^{-\lambda*t}$$
                Thus, the time for between mRNA production is exponentially distributed like 
                $$f(t)=\lambda e^{-\lambda t}$$
                
                This distribution is nice as it has the "memory-less" property that our discrete-time Markov chains had.
                Now, this has only given us a distribution of how long it takes between transcription events, not a total amount. 
    <br><br>
                Without deriving it, it can be shown that the distribution for the total number of "events" with exponentially distributed wait times has the following distribution:
    
                $$P(X_{t+s}-X_s=k)=e^{-\lambda t}\frac{(\lambda t)^k}{k!}$$
    
                This is known as a Poisson distribution, which is parameterized by \(\lambda\), the rate constant. 
                The distribution has the following properties:
                <ol>
                    <li>Mean of \(\lambda t\) </li>
                    <li>Variance of \(\lambda t\)</li>
                </ol>

                When doing kinetics when the amount of reactants are not in the "Law of Large Numbers" regime, the Poisson process can capture that it really is a probabilistic process for whether a given reactant will undergo a reaction and that there isn't a constant rate of conversion. 

                <h4>Sample Poisson Process Result</h4>

                <img src="PoissonGraph.png" alt="Poisson Process Graph" style="margin:auto; display: block;  width:clamp(400px,50vw, 800px)"/>
                Python code:
                <code style="margin: auto; width: 50%;"><pre>
def Inverse_Exp(p, lam):
    return -1* np.log(1-p)/lam

def Get_Number_Jumps(exp_cum_sum,t):
    return np.where(exp_cum_sum <= t, 1,0).sum()
np.random.seed(0)
dt = .001
uniform_dist = np.random.rand(500)
exp_sample = Inverse_Exp(uniform_dist, 1)
exp_sample
exp_cum_sum = exp_sample.cumsum()
exp_cum_sum

poisson_df = pd.DataFrame(columns=['t','X'])
for i in range(0,50001):
    poisson_df.loc[i] = [i*dt,
     Get_Number_Jumps(exp_cum_sum,i*dt)]
plt.figure(figsize=(9,6))
plt.scatter(poisson_df['t'],
    poisson_df['X'],s=.5,marker='s')
plt.xlabel("Time (s)")
plt.ylabel("X")
plt.title("Poisson Process with $\lambda=1$")
plt.show()</pre>
                </code>

                <br><br>
                <h3>Building Off of Poisson</h3>
                There are a number of ways by which we can extend the Poisson process. Here are a few examples:
                <ol>
                    <li>Variable size jumps drawn from some sort of distribution instead of \(P(J=+1)=1\) (Compound Poisson Process)</li>
                    <li>Transition rate \(\lambda\) is now a function of current value rather than a constant parameter (Birth Process)
                        <ul>
                            <li>Allow for decrease in value as well (Birth-Death Process)</li>
                        </ul>
                    </li>
                    <li>Non-exponentially distributed holding times (Renewal Process)</li>

                </ol>

                While not all possibilities will be covered in this textbook, all of these can be used to describe certain biological scenarios.

                <h4>Compound Poisson Process</h4>
                The Poisson process can be further generalized to allow for variable-sized jumps rather than just jumps of 1. 
                This is known as a "Compound Poisson Process." 
    
                <h5>Compound Poisson Process Example</h5>
                Note that the variable X is not continuous during jumps. Faint purple lines are added on the graph for visual clarity.
                <img src="CompoundPoissonGraph.png" alt="Compound Poisson Process Graph" style="margin:auto; display: block;  width:clamp(400px,50vw, 800px)"/>
                Python code:
                <code style="margin: auto; width: 50%;"><pre>
np.random.seed(1)
sigma = 0.5
normal_jumps = np.random.normal(scale=sigma,size=500)
def Inverse_Exp(p, lam):
    return -1* np.log(1-p)/lam

def Get_Number_Jumps(exp_cum_sum,t):
    return np.dot(np.where(exp_cum_sum <= t, 1,0),normal_jumps)

dt = .01
uniform_dist = np.random.rand(500)

exp_sample = Inverse_Exp(uniform_dist, 1)
exp_sample
exp_cum_sum = exp_sample.cumsum()
exp_cum_sum

poisson_df = pd.DataFrame(columns=['t','X'])
for i in range(0,5001):
    poisson_df.loc[i] = [i*dt,
     Get_Number_Jumps(exp_cum_sum,i*dt)]
plt.figure(figsize=(9,6))
plt.scatter(poisson_df['t'],
    poisson_df['X'],s=1.5,marker='s')
plt.plot(poisson_df['t'],
    poisson_df['X'],alpha=0.5,
    color='purple',linewidth='0.25')
plt.xlabel("Time (s)")
plt.ylabel("X")
plt.title(f"Compound Poisson Process with $\lambda=1$ and Jump$\sim N(0,{sigma**2})$")
plt.show()</pre>
                </code>
                <h4>Advanced Applications in Biology</h4>
                The classical example of stochastic processes in biology is mRNA expression levels - as it is a quantity that can both degrade and be produced at irregular intervals constantly. 
                This can be formulated as a Birth-Death process where the birth rate is the rate of mRNA transcription (potentially described as a constant or non-constant in case of some sort of feedback mechanism) and the death rate is proportional to the number of mRNA. 

    
                
            </div>
    
    
    
    
            
    
            <h2>Works Cited</h2>
            <ol>
                <li><a href="https://www.math.uchicago.edu/~lawler/finbook.pdf">https://www.math.uchicago.edu/~lawler/finbook.pdf</a></li>
            </ol>

        </div>
</body>
</html>
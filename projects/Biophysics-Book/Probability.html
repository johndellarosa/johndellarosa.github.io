<!DOCTYPE html>
<html lang="en-US">
    <head>

        <meta charset="UTF-8">
        <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2C44LTKBE1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-2C44LTKBE1');
</script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        
            <title>Probability, Statistics, & Entropy</title>
    
        <!-- Meta tags -->
        
        <meta name="keywords" content="Probability, statistics, Bayes, CDF, PDF">
        <meta name="author" content="John Della Rosa" >
        <meta name="description" content="This chapter reviews basic concepts of probability and statistics that are useful for understanding the later material.">
        
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
        <link rel="apple-touch-icon" sizes="180x180" href="https://johndellarosa.github.io/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="https://johndellarosa.github.io/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="https://johndellarosa.github.io/favicon-16x16.png">
        <link rel="manifest" href="https://johndellarosa.github.io/site.webmanifest">
            
        <link rel="stylesheet" href="https://johndellarosa.github.io/style.css"> 
        
        <!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
      

        <script src="../../math.js" type="text/javascript"></script> -->

    </head>
    <body>
        <div class="navbar">
            <b style="margin-right:10px">John Della Rosa</b>| 
            <a href="https://johndellarosa.github.io/index.html">Home</a>|
            <a href="https://johndellarosa.github.io/resume.html">Resume</a>
            <!-- <a href="./index.html#education">Education</a>
            <a href="./index.html#experience">Experience</a>
            <a href="./index.html#skills">Skills</a> -->
            |
            <a href="https://johndellarosa.github.io/biography.html">About</a>|
            <a href="https://johndellarosa.github.io/projects.html">Projects</a>|
            <a href="https://johndellarosa.github.io/Miscellaneous.html">Misc</a>|
            <a href="https://www.linkedin.com/in/johndellarosa/" target="_blank">Linkedin</a>|
            <a href="https://github.com/johndellarosa" target="_blank">Github</a>|
            <a href="https://play.google.com/store/apps/developer?id=JohnDellaRosa" target="_blank">Google Play</a>|
            <a href="https://apps.apple.com/us/developer/john-della-rosa/id1684177615" target="_blank">Apple Store</a>
        
        </div>
        <h2><a href= "Table-of-Contents.html">Biophysical Chemistry Textbook (Work in Progress)</a></h2>

<h3>by John Della Rosa</h3>
        <div id="text-contents" style="width:90%; margin:auto">
            <div id="Probability">
                <h1>Probability, Statistics, and Entropy</h1>
                <h2>Probability</h2>
                <h3>Defining terms</h3>
                Before we show any equations, we must define some terms and cover some basics of set theory. Let A and B be events. In this textbook, when we use the term <b>event</b>, we will mean it to be an outcome or set (group) of possible outcomes. 
                We will also denote \(\Omega\) to be the set of all possible outcomes. 
                <ul>
                    <li>An <b>element</b> is the term for the basic member of a set. This will represent a specfic outcome for most of our purposes.</li>
                    <li>P(A) is the probability of event A occurring. This corresponds to the probability of having any outcome in the set of outcomes included in A.
                        <ul>
                            <li>You can think of the probability of A as being a measure of the "size" of the set A (size does not refer to the number of elements in this analogy). The probability of each element need not be the same.</li>
                        </ul>

                    </li>
                    <li>\(A \subseteq B\) means that A is a <b>subset</b> of B. This means that all the outcomes included in A are also included in B. However, B could contain additional outcomes that are not in A.<ul>
                            <li>An example would be if A were rolling a 3 on a die and B were rolling an odd number on a die. </li>
                                <li>It is possible for A and B to be the same set of outcomes, which is captured by the underline in the notation. The notation for subset and proper subset is similar to comparing two real numbers. The open end poitns to the "larger" thing and an underline allows for equality to be included in the comparison.</li>
                            
                            <li>If we wish to state that A is a subset of B, but A is not the same as B, we will use the notation 
                                \(A \subset B\) and call A a <b>proper subset</b> of B.
                            </li>
                            <li>If \(A \subset B\), then \(P(A)\leq P(B)\)</li>
                        </ul>

                    </li>
                    <li>\(A\cup B\) is the <b>union</b> of A and B. This is the set of outcomes that are in A and/or B. This will be a set that is larger or equal in size than either A or B. The \(\lor\) can also be seen instead of \(\cup\), especially in logic.
                        <ul>
                            <li>If A is the set \(\{1,2,3\}\) and B is the set \(\{2,4,6\}\), then \(A\cup B = \{1,2,3,4,6\}\)</li>
                        </ul></li>
                    <li>\(A\cap B\) is the <b>intersection</b> of A and B. This is the set of outcomes that are in both A and B. The \(\land\) can also be seen instead of \(\cap\), especially in logic
                        <ul>
                            <li>If A is the set \(\{1,2,3\}\) and B is the set \(\{2,4,6\}\), then \(A\cap B = \{2\}\)</li>
                        </ul>
                    </li>
                    <li>\(B\setminus A\) is the set of outcomes that are in B, but not A. This is the set equivalent of subtraction.
                        <ul>
                            <li>In the special case of \(\Omega \setminus A\) can be written as \(A^{c}\) or \(\overline{A}\). This is called the <b>complement</b> of A and is the set of outcomes not in A. In logic, this can be seen as \(\neg A\)</li>
                        </ul>

                    </li>
                        
                </ul>
                We can take the probabilities of these resulting sets to see the probability of getting an outcome contained within them. 



                <h3>Basic Rules</h3>
                The sum of the probabilities of all possible outcomes must equal 1.
                Written for our set notation:
                $$P(\Omega)=1$$
                
                For discrete distributions this can be stated as 
                $$\sum P(x_i)=1$$
                and for continuous distributions, we can write
                $$\int_{-\infty}^{\infty}p(x)dx=1$$
                <h4>Inclusion-Exclussion Principle</h4>
                $$P(A\cup B)=P(A)+P(B)-P(A\cap B)$$
                The Inclusion-Exclussion Principle gives a relationship between two events, the probability of the union, and the probability of the intersection. This essentially makes sure we don't double count as \(A\cap B\) is included as an outcome in P(A) and P(B). 
                If A and B are mutually exclusive, then \(P(A\cap B)=0\). This can be thought of as the analogue of addition in probability.
                <h4>De Morgan's Laws</h4>
                De Morgan's laws describe how negation interactions with grouping of events. The statements can be rather formal, but verbally seem obvious. 
                <br>
                "If neither A nor B happened, then that means A didn't happen and B didn't happen"
                $$\neg(A \lor B)=(\neg A)\land (\neg B)$$
                $$(A \cup B)^c = A^c \cap B^c$$

    
                "If A and B didn't both happen, then that means either A didn't happen, B didn't happen, or neither happened"
                $$\neg(A \land B)=(\neg A)\lor (\neg B)$$
                $$(A \cap B)^c = A^c \cup B^c$$
                <h3>Cumulative Density Function</h3>
                The cumulative density function states the probability of getting the outcome being less than or equal to a given x. 
                We will define a <b>Cumulative Density Function</b> (CDF) formally as 
                
                $$F(x)=P(X\leq x)$$
                where X is the value of the random variable and x is a chosen value or cutoff point of interest.

                For discrete variables, we can formulate this as 

                $$F(x)=\sum_{x_i\leq x}p(x_i)$$
                where \(x_i\) is a possible value that X takes. We will call the function p(x) the <b>probability mass function</b> (PMF) for discrete variables. 

                <h4>Example with Binomial Distribution</h4>
                    <img src="BinomialPMFCDF.png" alt="Binomial PMF and CDF" style="margin:auto; display: block;  width:clamp(400px,50vw, 800px)"/>
                    Python code:
                    <code style="margin: auto; width: 50%;"><pre>
def combinations(n,k):
    return math.factorial(n)\
    /(math.factorial(k)*math.factorial(n-k))
def binomial_PMF(k,n,p):
    return combinations(n,k)*(p**k)*(1-p)**(n-k)
def binomial_CDF(k,n,p):
    accum = 0
    for i in range(0,k+1):
        accum += binomial_PMF(i,n,p)
    return accum
n = 8
x_values = [i for i in range(0,n+1)]
p = 0.6
fig = plt.figure()
plt.scatter(x_values,
            [binomial_PMF(k,n,p) for k in x_values])
plt.scatter(x_values,
            [binomial_CDF(k,n,p) for k in x_values],
            color='orange')
plt.legend(['PMF: $P(X=x_i)$','CDF: $P(X\leq x_i)$'])
plt.title("PMF and CDF for Binomial (p=0.6, n=8)")
plt.xlabel('k (number successes)')
plt.ylabel('Probability')
plt.show()</pre></code>


                <br><br>
                For continuous variables, we have 

                $$F(x)=\int_{-\infty}^xf(y)dy$$

                where f(y) is the probability density at y. We can think of this as the probability of  We will call the density function f(y) the <b>probability density function</b> (PDF) for continuous variables as opposed to PMF. 
                While we will sometimes use the notation of using p instead of f for the density function, it is important to emphasize that the probability density at a given value is <b>not</b> the probability of the random variable being that value. 
                Without invoking measure theory and the notion of what it means for something to have probability 0, a non-rigorous explanation is that since there are an infinite amount of real numbers in an interval, the probability of getting any specific one is infinitesimally small. Thus, it only makes sense to talk about an outcome being in a range of numbers rather than a specific value.


                <h4>Example with Arcsine Distribution</h4>
                <img src="ArcsinePDFCDF.png" alt="Arcsine PMF and CDF" style="margin:auto; display: block;  width:clamp(400px,50vw, 800px)"/>
                Python code:
                <code style="margin: auto; width: 50%;"><pre>
def arcsine_PDF(x):
    return 1/(np.pi*np.sqrt(x*(1-x)))
def arcsine_CDF(x):
    return 2/np.pi*math.asin(np.sqrt(x))

x_values = np.linspace(0.0,1,1000)

fig = plt.figure()
ax1 = fig.add_subplot(111)
ax2 = ax1.twinx()
ax1.set_ylim([0,5])

ax1.plot(x_values[1:-1],
            [arcsine_PDF(x) for x in x_values[1:-1]],label='PDF: $p(x)$')
ax1.set_ylabel('f(x)')

ax2.plot(x_values,
            [arcsine_CDF(x) for x in x_values],
            color='orange')
ax1.plot(np.nan,label='CDF: $P(X\leq x)$')
ax2.set_ylim([0,1])
ax1.legend()

plt.title("PDF and CDF for Arcsine Distribution")
ax1.set_xlabel('x')
ax2.set_ylabel('F(x)')
plt.show()</pre></code>


                <br><br>
                We can consequently calculate the probability of being between two values as follows:

                $$P(a\lt X\leq b) = F(b)-F(a)$$
                Which also means
                $$P(a \lt X \leq b)=\int_{a}^bf(y)dy$$

                Another common definition is that of the <b>survival function</b> which looks at the complement. We define this as 
                $$\bar{F}(x)=1-F(x)$$
Thus the survival function is also equivalent to 
$$\bar{F}(x)=P(X\gt x)$$

<h5>Example</h5>
Let X be an exponentially distributed variable with \(\lambda=2\), with the following density:

$$f(x)= \begin{cases}
                2\exp(-2x) & x\geq 0 \\
                0 & x \lt 0

\end{cases}$$

The probability that \(1\lt X \leq 2\) is given by

$$P(1\lt X \leq 2)=F(2)-F(1)$$
$$=\int_1^2 2\exp(-2x)dx$$

<img src="AreaUnderCurve.png" alt="Probability Continuous Variable" style="margin:auto; display: block;  width:clamp(400px,50vw, 800px)"/>
                Python code:
                <code style="margin: auto; width: 50%;"><pre>
lam = 2

def pdf_exp(x,lam):
    return np.where(x>=0, lam*np.exp(-lam*x),0)

x_values = np.linspace(0,6,1000)
plt.figure(figsize=(9,6))
plt.plot(x_values, pdf_exp(x_values,lam))
fill_x_values = np.linspace(1,2,300)
plt.fill_between(fill_x_values,pdf_exp(fill_x_values,lam))

plt.plot([0, 0], [0, 2], color='black')
plt.plot([0,6],[0,0],color='black')
plt.xlabel('x')
plt.ylabel('Density of X')
plt.title("Area Under Curve For Probability")
plt.legend(['Exp(2)'])
plt.show()</pre>
                </code>

                
    
    
                <h3>Conditional Probability</h3>
                Let A and B be two events. We denote the conditional probability of A occurring given B having occurred as \(P(A|B)\)
    
                This is defined mathematically as:
    
                $$P(A|B)\equiv \frac{P(A \cap B)}{P(B)}$$
                where \(P(A\cap B)\) is the probability of both A and B occurring.
                
    
    
                <h4>Bayes' Theorem</h4>
                Bayes' Theorem relates two events and the conditional probabilities of one upon another. 
                Let A and B two events with non-zero probabilities
                $$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$$
    
                <h3>Expected Value and Variance</h3>
                Given a probability distribution, what properties can we discern? 

                Let E[f(X)] denote the "Expected value," which can be thought of as the density-weighted mean, for a function f(x) on a distribution X. 

                We can calculate this as 

                $$E[f(X)]=\sum_{x_i}f(x)\times p(X=x_i)$$
                or in the continuous case
                $$E[f(X)]=\int_{-\infty}^{\infty}f(x)p(x)dx$$

                If we wanted to calculate the mean of a distribution, we can use f(X)=x and calculate the expectation.

                $$E[X]=\int_{-\infty}^{\infty}xp(x)dx$$

                Another common statistic that is used to describe a distribution is the variance, which is a measure of deviation from the mean.

                $$\text{Var}(X)=E[X^2]-(E[X])^2$$

                We can calculate this by separately calculating the expectations for \(E[X^2]\) and E[X]. The standard deviation is the square root of the variance. 



                <h5>Example</h5>
                The Bernoulli Distribution is given by 
                $$P(X=1)=p$$
                $$P(X=0)=1-p$$

                Calculate the mean and variance of the distribution.

                $$E[X]=\sum x_i p(x_i)$$
                $$=1\times p + 0 \times (1-p)$$
                $$=p$$

                $$E[X^2] = \sum x_i^2 p(x_i)$$
                $$=1^2 \times p + 0^2 \times (1-p)$$
                $$=p$$

                $$\text{Var}(X)=E[X^2]-(E[X])^2$$
                $$=p-p^2$$
                $$p(1-p)$$



                <h3>Multivariate Distributions</h3>

                

                A distribution can output a set of random variables.

                Let \(X_1,\dots, X_n\) be random variables, then we can define a multivariable distribution F:

                $$F(x_1,\dots,x_n)=P(X_1\leq x_i,\dots,X_n\leq x_n)$$
                <h4>Independence</h4>
                We say that \(X_1,\dots,X_n\) are independent if

                
                
                $$F(x_1,\dots,x_n)=\prod_{x_i}P(X_i\leq x_i)$$
                <h4>Marginal Distribution</h4>
                Sometimes we may only want to consider a subset of variables and focus on the distribution of those. We will call this the <b>marginal distribution</b>. 
                We can use the notation

                $$F_{X_i}(x_i)\equiv P(X_i\leq x_i)$$
                <h4>Multivariate density</h4>
                We can define the density of a multivariate distribution as 

                $$f(x_1,\dots,x_n)\equiv\frac{\partial^n}{\partial_1\cdots\partial_n}F(x_1,\dots,x_n)$$
                <h4>Marginal Density</h4>
                We can also define a function called the marginal density. Let us consider a bivariate distribution given by \(x_1\) and \(x_2\). 
                $$F_{X_1}(x_1)=\int_{-\infty}^{\infty}f(x_1,x_2)dx_2$$

                Using the marginal densities, we can arrive at an alternative definition of independence. Two random variables are independent if
                $$f(x_1,x_2)=f_{X_1}(x_1)f_{X_2}(x_2)\forall(x_1,x_2)$$
                <h4>Returning to Bayes - Conditional Distribution and Density</h4>
                Let us define the conditional distribution of \(X_1\) given \(X_2=x_2\)

                $$F_{X_1|X_2}(x_1|X_2)\equiv P(X_1\leq x_1|X_2=x_2)$$
                The marginal density is more useful in practice
                $$f_{X_1|X_2}(x_1|x_2)=\frac{\partial}{\partial x_1}F_{X_1|X_2}(x_1|x_2)=\frac{f(x_1,x_2)}{f_{X_2}(x_2)}$$

                Equivalently,

                $$f(x_1,x_2)=f_{X_1|X_2}(x_1|x_2)f_{X_2}(x_2)$$

                <h3>Covariance and Correlation</h3>
                How do we quantify how two variables co-move?
                <br><br>
                Let us define the Covariance between \(X_1\) and \(X_2\) as

                $$\text{Cov}(X_1,X_2)=E[X_1X_2]-E[X_1]E[X_2]$$

                The special case of the covariance of a random variable with itself is equal to the variance. 
                <br><br>
                We can normalize this into the <b>Pearson correlation</b> (often just called correlation) as follows:

                $$\rho(X_1,X_2)=\frac{\text{Cov}(X_1,X_2)}{\sqrt{\text{Var}[X_1]\text{Var}[X_2]}}$$

                What must be emphasized is that a correlation of 0 does not mean that two variables are independent. 
                A correlation of 0 is a <b>necessary but not sufficient</b> condition. For example, take a random variable that is distributed like \(X\sim N(0,1)\) and another variable Y=abs(X). The correlation is 0, but they are not independent.
<br><br>
                Also, Pearson correlation only captures linear behavior between two variables. Another metric for monotonic behaviour between two random variables is <b>Spearman correlation</b>. Kendall's tau coefficient is a third way. 

                <h2>Entropy</h2>
                <h3>Multiplicity</h3>
    
                If we flip a coin twice, the most likely outcome for the number of heads we get is 1. 
                How is this possible if the coins are fair and independent? The answer has to do with that there are two possible sequences which will give you 1 head, TH and HT, while there are only 1 sequence each for 0 heads and 2 heads. 
                We will call this phenomenon of their being different number of sequences for each outcome "multiplicity."
                To further use the coin analogy, we will call the specific sequence the <b>microstate</b> and the total number of heads to be the <b>state</b> or <b>macrostate</b>. 
                Each microstate is equally likely, but there are 2 microstates that correspond to the 1 heads macrostate. 
                
                <br><br>
                Given M coin flips, the number of ways to get N heads would be given as:
                $$W=\frac{M!}{N!(M-N)!}$$
                
                However, this restricts us to only 2 outcomes. What if we require more? <br><br>
    
                A generalized multiplicity formula for arranging Z types of things in M spaces is
                $$W=\frac{M!}{\prod N_{i}!}=\frac{M!}{N_{1}!*N_{2}!*...*N_{Z}!}$$
                If there are only two possible types and M total and N of type 1, then \(N_2=M-N\) and it reduces to
                $$W=\frac{M!}{N!(M-N)!}$$
    
                <h3>Definitions of Entropy</h3>
                Entropy is typically described as being a measure of "disorder," but how does that manifest? 
                With words, we can describe entropy for now as a measure of how mixed a system is or how many microstates a given macrostate has. 
                <br><br>
    
                There are 3 main formulas that we will be considering:
                $$S=k_B\ln(W)$$
                $$S=-k_B\sum p\ln(p)$$
                $$dS=\frac{dq}{T}$$
                These will be called the statistical definition, the probabilistic definition, and thermodynamic definition respectively. 
    
    
                <h3>Extensive and Intensive Properties</h3>
                A property of a system is said to be <b>extensive</b> if it is proportional to the size of the system. One example is mass; if the system is 1L of water, going to 2L of water will double the mass. These properties are often not ratios and can often be intuited via thought experiment. 
    <br><br>
                A property of a system is said to be <b>intensive</b> if it remains constant when a system is scaled. Density is an example of an intensive property. In the previous example, the density of the system does not change when you go from 1L of water to 2L of water. Mass and volume of the system both double, which cancel out when you take the ratio to get density. 
    <br><br>
                Some properties are neither extensive not intensive if they scale but in a non-linear proportional way. 
                The most notable example is multiplicity. This can be shown if every number in the above calculation is doubled due to the factorial operator. 
                Entropy at large scales behaves like an extensive property, but at very small scales, this does not always hold. 
                
            
                <h3>Normal Distribution</h3>

                Also called a Gaussian or Bell-curve, the Normal distribution is an essential distribution to know. 
                It is parameterized by two values:
                <ul>
                    <li>The mean, \(\mu\), which states the center of the distribution</li>
                    <li>The variance, \(\sigma^2\), which describes the width of the distribution</li>
                </ul>

                Some conventions will parameterize it using the standard deviation rather than its variance. 
                These are equivalent as the standard deviation is the square root of the variance and there is a 1-to-1 mapping. 
                In this book, we will use the following notation to state that a variable X is distributed normally with mean, \(\mu\) and variance \(\sigma^2\):

                $$X\sim N(\mu,\sigma^2)$$

                Again, in some sources, the second parameter will be the standard deviation instead, but in this text, it will always be the variance unless stated otherwise.

                <br><br>

                This is a continuous probability distribution whose density is given by

                $$f(x)=\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}$$

                If the normal distribution has parameters \(\mu=0\) and \(\sigma^2=1\) then we refer to it as a <b>standard normal distribution</b>.
                <br><br>

                <h4>Properties</h4>
                
                <ul>
                    <li>Has non-zero probability density everywhere</li>
                    <li>Symmetric</li>
                    <li>Antiderivative does not have a closed-form</li>
                </ul>

                <h3>Law of Large Numbers</h3>

                <h3>Central Limit Theorem</h3>



            </div>
            <div id="Practice Problems">
                
                <h2>Practice Problems</h2>

                <ol>
                    <li>The exponential distribution is given by \(f(x)=ae^{-ax}\) for \(x\geq 0\) and 0 for \(x \lt 0\). Determine the mean and variance.
                        The following identities may be useful:
                        <ol>
                            <li>\(\int xe^{-ax}dx=-\frac{e^{-ax}(ax+1)}{a^2}+c\)</li>
                            <li>\(\int x^2e^{-ax}dx=-\frac{e^{-ax}(a^2x^2+2ax+2)}{a^3}+c\)</li>
                        </ol>
                    </li>

                </ol>
            </div>

        </div>
        <br>
        <br>
</body>
</html>